# ğŸ Bio-D-Scan â€” Multi-Modal Insect Detection & Classification System

> **Real-time insect detection, tracking, and classification** using edge AI on a Raspberry Pi 5 with Hailo AI HAT+ accelerator, combining computer vision and audio spectrogram analysis.

**Advisor:** Dr. Khurram Jadoon &nbsp;|&nbsp; **Co-Advisor:** Dr. Muhammad Hanif  
**Faculty of Computer Science and Engineering**  
**Phase:** Proof of Concept / Prototype  
**Author:** Muneeb Bin Nasir

---

## ğŸ“‹ Poster

<p align="center">
  <img src="bio-d-scan/Poster.jpeg" alt="Bio-D-Scan Project Poster" width="100%"/>
</p>

---

## ğŸ“– Overview

**Bio-D-Scan** is a multi-modal biodiversity monitoring system that combines **visual insect detection** (YOLO object detection) with **audio classification** (spectrogram-based CNN) for comprehensive insect identification. The system runs on a Raspberry Pi 5 equipped with a Hailo-8L AI accelerator (26 TOPS), enabling real-time inference at **~25 FPS** directly on the edge device.

### Key Capabilities

- **Real-time Detection** â€” YOLO-based insect detection running on Hailo AI hardware
- **Multi-Object Tracking** â€” Hungarian algorithm tracker with path recording, entry/exit detection, and movement analysis
- **Audio Classification** â€” Mel spectrogram-based CNN for insect sound identification *(in progress)*
- **Cloud Sync** â€” Automatic upload to Supabase with offline queue (store & forward)
- **Live Dashboard** â€” Streamlit web interface with species distribution, timelines, trajectory visualization, and session management

### Detected Species

| Class ID | Species    |
|----------|------------|
| 0        | Butterfly  |
| 1        | Beetle     |
| 2        | Ladybug    |
| 3        | Bee        |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Raspberry Pi 5                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ PiCamera â”‚â”€â”€â”€â–¶â”‚  Hailo-8L    â”‚â”€â”€â”€â–¶â”‚  Insect Tracker    â”‚     â”‚
â”‚  â”‚   (RGB)  â”‚    â”‚  YOLO Model  â”‚    â”‚  (Hungarian Algo)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  ~25 FPS     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                  â”‚
â”‚                                               â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Mic    â”‚â”€â”€â”€â–¶â”‚ Spectrogram  â”‚â”€â”€â”€â–¶â”‚   Cloud Upload     â”‚     â”‚
â”‚  â”‚ (Audio)  â”‚    â”‚  CNN Model   â”‚    â”‚   (Supabase)       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                               â”‚                  â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚                  â”‚
â”‚                  â”‚ Offline Queueâ”‚â—€â”€â”€â”€ Fallback â”‚                  â”‚
â”‚                  â”‚ (Store+Fwd)  â”‚              â”‚                  â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚   Supabase Cloud     â”‚
                                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                                  â”‚  â”‚ PostgreSQL DB  â”‚   â”‚
                                  â”‚  â”‚   (Tracks,     â”‚   â”‚
                                  â”‚  â”‚   Sessions,    â”‚   â”‚
                                  â”‚  â”‚   Statistics)  â”‚   â”‚
                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                                  â”‚  â”‚ Object Storage â”‚   â”‚
                                  â”‚  â”‚  (Images)      â”‚   â”‚
                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  Streamlit Dashboard  â”‚
                                  â”‚  (Real-time Charts,   â”‚
                                  â”‚   Trajectory Viewer)  â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
BIO-D-SCAN/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ yolo_training.ipynb              # YOLO model fine-tuning notebook
â”œâ”€â”€ split_dataset.py                 # Train/Val/Test dataset splitter
â”œâ”€â”€ yolo11n.pt                       # YOLO11n pretrained weights
â”œâ”€â”€ yolov8n.pt                       # YOLOv8n pretrained weights
â”‚
â””â”€â”€ bio-d-scan/                      # Main application
    â”œâ”€â”€ main.py                      # Main detection loop (PiCamera2 + Hailo)
    â”œâ”€â”€ test_video.py                # Video-based testing (no camera needed)
    â”œâ”€â”€ labels.txt                   # Class labels (Butterfly, Beetle, Ladybug, Bee)
    â”œâ”€â”€ .env.example                 # Environment variable template
    â”œâ”€â”€ Poster.jpeg                  # Project poster
    â”œâ”€â”€ Audio Classification using Spectrograms.ipynb  # Audio model training
    â”‚
    â”œâ”€â”€ models/                      # Compiled Hailo models (.hef)
    â”‚   â”œâ”€â”€ insect_detector_yolov11n.hef
    â”‚   â”œâ”€â”€ insect_detector_yolov8n.hef
    â”‚   â””â”€â”€ insects_detector_old.hef
    â”‚
    â”œâ”€â”€ src/                         # Core modules
    â”‚   â”œâ”€â”€ detector.py              # Hailo inference wrapper
    â”‚   â”œâ”€â”€ tracker.py               # Multi-object tracker (Hungarian algorithm)
    â”‚   â”œâ”€â”€ database.py              # Supabase upload + session management
    â”‚   â””â”€â”€ queue_manager.py         # Offline queue (store & forward)
    â”‚
    â”œâ”€â”€ dashboard/                   # Web dashboard
    â”‚   â””â”€â”€ app.py                   # Streamlit dashboard application
    â”‚
    â””â”€â”€ queue/                       # Local queue for failed uploads
        â””â”€â”€ *.json                   # Queued track data
```

---

## âš™ï¸ Hardware Requirements

| Component | Specification |
|-----------|---------------|
| **SBC** | Raspberry Pi 5 |
| **AI Accelerator** | Hailo-8L AI HAT+ (26 TOPS) |
| **Camera** | Raspberry Pi Camera Module (PiCamera2 compatible) |
| **Microphone** | USB microphone *(for audio classification)* |
| **Storage** | microSD card (32GB+ recommended) |

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/BIO-D-SCAN.git
cd BIO-D-SCAN/bio-d-scan
```

### 2. Install Dependencies

```bash
pip install opencv-python numpy scipy picamera2 hailo-platform
pip install supabase python-dotenv
pip install streamlit pandas plotly            # For the dashboard
pip install ultralytics                        # For video testing / training
pip install librosa tensorflow scikit-learn    # For audio classification
```

### 3. Configure Environment Variables

```bash
cp .env.example .env
```

Edit `.env` with your Supabase credentials:

```env
PROJECT_URL=https://your-project.supabase.co
API_KEY=your-anon-key-here
DEVICE_ID=rpi5_01
```

### 4. Set Up Supabase

Create the following in your Supabase project:

- **Storage Bucket:** `insects` (public)
- **Tables:**
  - `tracks` â€” stores detection data (tracker_id, type, confidence, timestamp, image_url, path_points, distance_traveled, duration_seconds, entry_point, exit_point, frame_count, session_id)
  - `sessions` â€” stores monitoring sessions (device_id, started_at, ended_at, location, is_active, total_detections)
  - `statistics` â€” stores aggregated stats per session (session_id, insect_type, count, last_updated)
- **RPC Function:** `increment_session_detections`

---

## ğŸ¯ Usage

### Run on Raspberry Pi (Live Camera)

```bash
cd bio-d-scan
python main.py -m models/insect_detector_yolov11n.hef -l labels.txt
```

This will:
1. Start the PiCamera2 with a live QTGL preview
2. Run YOLO inference on each frame via the Hailo accelerator
3. Track insects across frames using the Hungarian algorithm
4. When an insect leaves the frame, capture its best image with trajectory overlay
5. Upload the track data and image to Supabase (or queue locally if offline)

### Test with a Video File (No Camera Required)

```bash
cd bio-d-scan
python test_video.py --video path/to/insects.mp4 --model models/yolov8n.pt --display
```

Options:
- `--video` â€” Path to input video file
- `--model` â€” Path to YOLO model (`.pt` or `.onnx`)
- `--display` â€” Show live preview window
- `--conf` â€” Confidence threshold (default: 0.5)
- `--skip-upload` â€” Run locally without Supabase

### Launch the Dashboard

```bash
cd bio-d-scan
streamlit run dashboard/app.py
```

The dashboard provides:
- **Species distribution** pie chart
- **Detection timeline** area chart
- **Movement patterns** (entry/exit point analysis)
- **Trajectory viewer** with interactive path plots
- **Recent detections** table with images
- **Session filtering** and time range controls

---

## ğŸ§  Model Training

### Visual Detection (YOLO)

The training notebook ([yolo_training.ipynb](yolo_training.ipynb)) fine-tunes both **YOLO11n** and **YOLOv8n** on a custom insect dataset.

| Parameter | Value |
|-----------|-------|
| **Dataset Classes** | Butterfly, Beetle, Ladybug, Bee |
| **Dataset Split** | 70% Train / 20% Val / 10% Test |
| **Image Size** | 640 Ã— 640 |
| **Epochs** | 100 |
| **Batch Size** | 16 |
| **Metric (mAP@50)** | **0.78** |
| **Inference Speed** | ~25 FPS on RPi 5 |

Trained models are exported to **ONNX** format and then compiled to **HEF** format for deployment on the Hailo-8L accelerator.

### Audio Classification (Spectrograms)

The notebook ([Audio Classification using Spectrograms.ipynb](bio-d-scan/Audio%20Classification%20using%20Spectrograms.ipynb)) trains a CNN classifier on insect sounds:

1. Audio files are converted to **Mel spectrograms** using `librosa`
2. Spectrogram images are fed into a **3-layer CNN** (TensorFlow/Keras)
3. The model classifies insect species from their sound patterns
4. Dataset: [InsectSound1000](https://www.kaggle.com/datasets/hesi0ne/insectsound1000) from Kaggle

> **Status:** Audio classification is functional. Multi-modal fusion (combining visual + audio predictions) is in progress.

---

## ğŸ” Tracking Algorithm

The `InsectTracker` uses the **Hungarian algorithm** (via `scipy.optimize.linear_sum_assignment`) for optimal detection-to-track assignment:

1. **Cost Matrix** â€” Combines normalized Euclidean distance (60% weight) and bounding box area dissimilarity (40% weight)
2. **Track Lifecycle:**
   - **Created** when an unmatched detection appears
   - **Updated** when matched to a detection in the next frame
   - **Lost** when not matched for consecutive frames
   - **Finalized** when lost for `max_lost` frames (default: 20) and minimum distance traveled is met
3. **Class Voting** â€” Each frame's classification is a vote; the majority class across the track's lifetime is the final label
4. **Best Image** â€” The frame with the highest confidence score is saved as the representative image
5. **Path Recording** â€” Centroid history, entry/exit points, distance traveled, and duration are computed per track

---

## ğŸ“Š Dashboard Preview

The Streamlit dashboard ([dashboard/app.py](bio-d-scan/dashboard/app.py)) provides real-time monitoring:

| Feature | Description |
|---------|-------------|
| **Total Detections** | Count of insects detected |
| **Species Detected** | Number of unique species |
| **Avg. Confidence** | Mean detection confidence |
| **Avg. Track Duration** | Mean time insects are visible |
| **Species Pie Chart** | Distribution of detected species |
| **Timeline Chart** | Detections over time by species |
| **Entry/Exit Analysis** | Bar charts of movement directions |
| **Trajectory Viewer** | Interactive XY path plots per track |
| **Detection Table** | Detailed table with images and metadata |

---

## ğŸ”„ Offline Queue System

When internet connectivity is unavailable, the system automatically queues failed uploads locally:

1. Track data and images are saved to the `queue/` directory
2. A background thread retries uploads every 60 seconds
3. Successfully uploaded items are cleaned up automatically
4. The queue persists across restarts

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Hardware** | Raspberry Pi 5, Hailo-8L AI HAT+ (26 TOPS) |
| **Camera** | PiCamera2 |
| **Object Detection** | YOLO11n / YOLOv8n (Ultralytics) |
| **Model Runtime** | Hailo Runtime (HEF format) |
| **Tracking** | Custom Hungarian Algorithm Tracker (SciPy) |
| **Audio ML** | TensorFlow / Keras CNN + Librosa |
| **Backend** | Supabase (PostgreSQL + Object Storage) |
| **Dashboard** | Streamlit + Plotly |
| **Language** | Python |

---

## ğŸ“„ License

This project is developed as part of an academic final year project at the Faculty of Computer Science and Engineering.

---

## ğŸ™ Acknowledgments

- **Dr. Khurram Jadoon** â€” Project Advisor
- **Dr. Muhammad Hanif** â€” Co-Advisor
- [Ultralytics](https://github.com/ultralytics/ultralytics) â€” YOLO models
- [Hailo](https://hailo.ai/) â€” Edge AI accelerator platform
- [Supabase](https://supabase.com/) â€” Backend-as-a-Service
- [InsectSound1000 Dataset](https://www.kaggle.com/datasets/hesi0ne/insectsound1000) â€” Audio classification dataset
